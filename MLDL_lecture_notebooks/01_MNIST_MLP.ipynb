{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "01_MNIST_MLP.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_NZwOwd9KsKz"
      },
      "source": [
        "# 01. Character recognition of MNIST dataset using MLP\n",
        "\n",
        "\n",
        "---\n",
        "## Purpose\n",
        "Carry out character recognition of the MNIST dataset using a Multilayer Perceptron (MLP).\n",
        "For evaluation, calculate the recognition rate of each class using a confusion matrix."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-0vTan1NYLI"
      },
      "source": [
        "## Dataset\n",
        "\n",
        "\n",
        "We use the [MNIST Dataset](http://yann.lecun.com/exdb/mnist/) to train and test character recognition in this tutorial. The MNIST dataset is a dataset composed of images depicting numerical digits from 0 to 9. \n",
        "\n",
        "We process the images of the MNIST dataset as shown below to allow easier recognition using black and white values.\n",
        "\n",
        "\n",
        "\n",
        "![MNIST_sample.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/143078/559938dc-9a99-d426-010b-e000bca0aac6.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RsGSLNkYQmkG"
      },
      "source": [
        "## Import modules\n",
        "First, import the necessary modules.\n",
        "\n",
        "For this tutorial, import `torch` (PyTorch)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLeGt2xaNFOB"
      },
      "source": [
        "from time import time\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import torchsummary"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ue60y-upamyo"
      },
      "source": [
        "## Read and confirm dataset\n",
        "\n",
        "Load the training data (MNIST dataset).\n",
        "\n",
        "Confirm the size of the loaded data. The training data size is 60,000 images. The testing data size is 10,000 images. The size of each data is 28x28 pixels, 786 dimensions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7zpMk-4axYm"
      },
      "source": [
        "train_data = torchvision.datasets.MNIST(root=\"./\", train=True, transform=transforms.ToTensor(), download=True)\n",
        "test_data = torchvision.datasets.MNIST(root=\"./\", train=False, transform=transforms.ToTensor(), download=True)\n",
        "\n",
        "print(type(train_data.data), type(train_data.targets))\n",
        "print(type(test_data.data), type(test_data.targets))\n",
        "print(train_data.data.size(), train_data.targets.size())\n",
        "print(test_data.data.size(), test_data.targets.size())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MN-KoymJbe25"
      },
      "source": [
        "### Display MNIST dataset\n",
        "\n",
        "Display the images in the MNIST dataset. Here we use a program that uses matplotlib to display multiple images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehg-aZh8be9Z"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "cols = 10\n",
        "\n",
        "plt.clf()\n",
        "fig = plt.figure(figsize=(14, 1.4))\n",
        "for c in range(cols):\n",
        "    ax = fig.add_subplot(1, cols, c + 1)\n",
        "    ax.imshow(train_data[c][0].view(28, 28), cmap=plt.get_cmap('gray'))\n",
        "    ax.set_axis_off()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G418kZOgToXR"
      },
      "source": [
        "## Display MNIST dataset\n",
        "\n",
        "Display the images in the MNIST dataset. Here we use a program that uses matplotlib to display multiple images.\n",
        "\n",
        "Define neural network model\n",
        "Define the neural network. For this example, we create a three-layer neural network consisting of the input layer, intermediate layer, and output layer. \n",
        "The number of units in the input layer depends on the size of the input data. In this case, the image size (pixels) is `28 x 28 = 784`, so we specify a one-dimensional array of pixel values as the sorted data to be inputted.\n",
        "\n",
        "The numbers of units in the intermediate layer and output layer are given by parameters `n_hidden` and `n_out`, respectively. In PyTorch, each layer is defined by passing arguments to these parameters in the `__init__` function. Each layer is treated as a linear function. The activation function is specified by `self.act`. Here we specify the sigmoid function as the activation function.\n",
        "\n",
        "The `forward` function describes how to connect and process the defined layers. The `forward` function’s parameter `x` represents the input data. This parameter’s argument is inputted sequentially to the intermediate layer `l1` defined by the `forward` function and the activation function `act`. The output is `h1`, which is passed to input layer `l2`. The output of that layer is called `h2`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FJhkBJnTuPd"
      },
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self, n_hidden, n_out):\n",
        "        super().__init__()\n",
        "        self.l1 = nn.Linear(28*28, n_hidden)\n",
        "        self.l2 = nn.Linear(n_hidden, n_out)\n",
        "        self.act = nn.Sigmoid()\n",
        "        \n",
        "    def forward(self, x):\n",
        "        h1 = self.act(self.l1(x))\n",
        "        h2 = self.l2(h1)\n",
        "        return h2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OF_0s3vBYBES"
      },
      "source": [
        "## Create neural network\n",
        "\n",
        "Create the neural network defined by the program above.\n",
        "\n",
        "First, we define the numbers of units of the intermediate layer and output layers. Here, we set `hidden_num`, the number of units in the intermediate layers, as 16. We set `out_num`, the number of units in output layers, as 10. This number corresponds to the number of classes in the MNIST dataset.\n",
        "\n",
        "The network model is defined by passing the numbers of units in each layer as the arguments of `MLP` class defined above.\n",
        "\n",
        "For training, we use stochastic gradient descent with momentum (SGD with momentum) as the optimization method. We set the learning rate as 0.01 and the momentum to 0.9 in the arguments. \n",
        "\n",
        "Finally, `torchsummary.summary()` is used to display detailed information about the defined network. The first argument specifies the model for which to display details. The second argument specifies the size of the data being input to the network. In this way, you can confirm the structure of the neural network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FTAUhy9qX4QU"
      },
      "source": [
        "# define the number of units\n",
        "hidden_num = 16\n",
        "out_num = 10\n",
        "\n",
        "# create network model\n",
        "model = MLP(n_hidden=hidden_num, n_out=out_num)\n",
        "\n",
        "# setup optimization method\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "# display detailed information about the defined network\n",
        "torchsummary.summary(model, (1, 28*28), device='cpu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iGfy76HRYy4S"
      },
      "source": [
        "## Training\n",
        "Carry out training by using the loaded MNIST dataset and the created neural network.\n",
        "\n",
        "We set the data size for calculating errors for one pass (mini-batch size) as 100 and the number of training epochs as 10.\n",
        "\n",
        "Next, we define the data loader. The data loader uses the training dataset (`train_data`) that was loaded above and creates an object that reads the data in the mini-batch size as specified by the assignment statement below. For this training, we set shuffle=True to specify that the data is to be read randomly each time. \n",
        "\n",
        "Next, we set the error function. Because we are dealing with a classification problem here, we define `criterion` to be `CrossEntropyLoss` to calculate cross entropy error.\n",
        "\n",
        "Begin training.\n",
        "\n",
        "For each update, the data to be learned and the teacher data are given the names `image` and `label`, respectively. The training model is given an image and obtains the probability `y` for each class. The error between each class’s probability `y` and the teacher `label` is calculated by `criterion`. The recognition accuracy is also calculated. The error is then backpropagated by the `backward` function to update the neural network.  \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0iI0zC-ZSY2"
      },
      "source": [
        "# set mini-batch size and the number of training eopchs\n",
        "batch_size = 100\n",
        "epoch_num = 10\n",
        "\n",
        "# define data loader\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# set error (loss) function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# swich network execution mode as training mode\n",
        "model.train()\n",
        "\n",
        "# begin training\n",
        "for epoch in range(1, epoch_num+1):\n",
        "    sum_loss = 0.0\n",
        "    count = 0\n",
        "    \n",
        "    for image, label in train_loader:\n",
        "        image = image.view(image.size()[0], -1)\n",
        "        y = model(image)\n",
        "        \n",
        "        loss = criterion(y, label)\n",
        "        model.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        sum_loss += loss.item()\n",
        "        \n",
        "        pred = torch.argmax(y, dim=1)\n",
        "        count += torch.sum(pred == label)\n",
        "\n",
        "    print(\"epoch:{}, mean loss: {}, mean accuracy: {}\".format(epoch, sum_loss/600, count.item()/60000.))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ti1LytKAZYIO"
      },
      "source": [
        "## Testing\n",
        "\n",
        "Evaluate the trained network and confirm the recognition rate on the testing data. Apply `model.eval()` to change network operations to evaluation mode. This enables different operations (e.g. dropout) to behave differently in evaluation mode instead of training mode. Apply `torch.no_grad()` to carry out operations without keeping gradient information that is required during training.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "635DQ0ATYBJN"
      },
      "source": [
        "# define data loader\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=100, shuffle=False)\n",
        "\n",
        "# swich network execution mode as evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# begin evaluation\n",
        "count = 0\n",
        "with torch.no_grad():\n",
        "    for image, label in test_loader:\n",
        "        image = image.view(image.size()[0], -1)\n",
        "        y = model(image)\n",
        "\n",
        "        pred = torch.argmax(y, dim=1)\n",
        "        count += torch.sum(pred == label)\n",
        "\n",
        "print(\"test accuracy: {}\".format(count.item() / 10000.))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7YT4hqE3Ycpg"
      },
      "source": [
        "## Problem\n",
        "\n",
        "### 1. Change the neural network structure and confirm the change in recognition accuracy.\n",
        "\n",
        "**Hint: The following items can change the neural network structure.**\n",
        "* Number of units in intermediate layers\n",
        "*\tNumber of layers\n",
        "*\tThe activation function\n",
        "  * For example, `nn.Tanh()` or `nn.ReLU()`, `nn.LeakyReLU()`, etc.\n",
        "  * ther activation functions that can be used in PyTorch are summarized on [this page](https://pytorch.org/docs/stable/nn.html#non-linear-activations-weighted-sum-nonlinearity).\n",
        "\n",
        "\\* After changing the neural network structure, use the function `torchsummary.summary()` to view changes in the number of parameters.\n",
        "\n",
        "  \n"
      ]
    }
  ]
}