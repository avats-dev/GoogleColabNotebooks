{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"04_augmentation.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.9"}},"cells":[{"cell_type":"markdown","metadata":{"id":"wJU2RPpSvlQT"},"source":["# 04. Object recognition of CIFAR10 dataset using data augmentation\n","\n","\n","---\n","## Purpose\n","Carry out object recognition of the CIFAR10 dataset. The structure of this program is similar to the MNIST character recognition program, so refer to that tutorial for a basic explanation. This page describes differences with the MNIST character recognition program.\n","\n","Compute neural network operations by using the GPU．Also, confirm the effect of data augmentation on learning.\n"]},{"cell_type":"markdown","metadata":{"id":"5rQGfxWYK_4O"},"source":["## Preparations\n","\n","### Confirm and change Google Colaboratory settings\n","\n","In this tutorial, we use PyTorch to implement a neural network and carry out training and evaluation. **To process operations using the GPU, go to the menu bar at the top of screen and choose Runtime -> Change runtime type -> Hardware accelerator -> GPU.**"]},{"cell_type":"markdown","metadata":{"id":"C2tsYagqvloK"},"source":["## Dataset\n","\n","### CIFAR10 dataset\n","\n","We use the CIFAR10 dataset for object recognition in this tutorial. The CIFAR10 dataset is composed of images in 10 different classes representing airplanes, dogs, etc.\n","\n","![CIFAR10_sample.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/176458/b6b43478-c85f-9211-7bc6-227d9b387af5.png)"]},{"cell_type":"markdown","metadata":{"id":"Xo4jjpmwvle1"},"source":["## Import modules\n","\n","\n","First, import the necessary modules.\n","\n","\n","### Confirm GPU settings\n","\n","Confirm computation using GPU is enabled.\n","\n","If `Use CUDA: True` is displayed, it is possible to use the GPU to perform computation in PyTorch. If Use CUDA: False is displayed, start from the procedures given in “Confirm and change Google Colaboratory settings” above and change the settings. Then import the modules again.\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"iCeaCulfvlao"},"source":["# import modules\n","from time import time\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","\n","import torchvision\n","import torchvision.transforms as transforms\n","\n","import torchsummary\n","\n","# confirm GPU settings\n","use_cuda = torch.cuda.is_available()\n","print('Use CUDA:', use_cuda)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ppjeW5MbysXC"},"source":["## Read and dataset and Data Augmentation\n","\n","Load the training data (CIFAR10 dataset)．\n","\n","At this time, we define `transform_train` and `transform_test`, which pre-process training and testing images. `transform_train` is defined using `transforms.Compose()`. `transforms.Compose()` takes image data as its argument and returns processed image data, which is defined for use in training and evaluation.\n","\n","### In case of no augmentation\n","First, definition if no data augmentation is performed is explained.\n","As `transforms.Compose([transforms.ToTensor()])` shows, the list enclosed by the parentheses of function `transforms.ToTensor()` is passed as the argument. This function converts data to a tensor, which can be handled by PyTorch. At the same time, pixel values `[0, 255]` are normalized to `[0.0, 1.0]`. \n","\n","\n","### In case of augmentation\n","\n","If applying some types of augmentation, pass a list of transform functions you wish to perform as the argument of `transforms.Compose()`. In the example below\n","```\n","[transforms.RandomCrop(32, padding=1),\n"," transforms.RandomHorizontalFlip(),\n"," transforms.ToTensor()]\n","```\n","three functions are given in the list, which is passed as the argument of `transforms.Compose()`. `RandomCrop()` randomly crops an image. It returns a redefined CIFAR10 image, which is originally 32x32 pixels, by resizing it. `RandomHorizontalFlip()` defines an image by randomly flipping it left/right. `transforms.ToTensor()` converts augmented image data to a tensor and normalizes the pixel values.\n","\n","Because augmentation is not applied to the testing data, only the `ToTensor()` function is used to define the data.\n"]},{"cell_type":"code","metadata":{"id":"K_xx-TkVvls6"},"source":["# NO augmentation #####\n","transform_train = transforms.Compose([transforms.ToTensor()])\n","transform_test = transforms.Compose([transforms.ToTensor()])\n","\n","# augmentation #####\n","# transform_train = transforms.Compose([transforms.RandomCrop(32, padding=1),\n","#                                       transforms.RandomHorizontalFlip(),\n","#                                       transforms.ToTensor()])\n","# transform_test = transforms.Compose([transforms.ToTensor()])\n","\n","train_data = torchvision.datasets.CIFAR10(root=\"./\", train=True, transform=transform_train, download=True)\n","test_data = torchvision.datasets.CIFAR10(root=\"./\", train=False, transform=transform_test, download=True)\n","\n","print(train_data)\n","print(test_data)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xgDd3iX2zmSV"},"source":["## Defines neural network\n","\n","Define the convolutional neural network.\n","\n","The network in this tutorial consists of two convolutional layers and three fully connected layers.\n","\n","The first convolutional layer has 1 input channel, 16 output feature maps, and a 3x3 convolution filter. The second convolutional layer has 16 input channels, 32 output feature maps, and convolution filter that also has a size of 3x3. The first fully connected layer has an indefinite number of units and 1024 output units. The next fully connected layer has 1024 input units and 1024 output units. The output layer has 1024 input units and 10 output units. We define the composition of each layer using the `__init__` function.\n","\n","\n","The `forward` function describes how to connect and process the defined layers. The `forward` function’s parameter x represents the input data. This parameter’s argument is inputted to conv1 defined by the `__init__` function. The output of that function is passed to the activation function relu. This output is passed to max_pooling_2d. The result of pooling is outputted as h, which is passed to conv2 for convolutional processing and pooling. This output h is passed to l1 for fully connected layer processing. The second convolutional layer is also processed using the same procedures. Finally, after processing of l3 fully connected layer, the output h is returned.\n"]},{"cell_type":"code","metadata":{"id":"TNHnp_YczmY3"},"source":["class CNN(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1)\n","        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n","        self.relu = nn.ReLU()\n","        self.pool = nn.MaxPool2d(2, 2)\n","        self.l1 = nn.Linear(8 * 8 * 32, 1024)\n","        self.l2 = nn.Linear(1024, 1024)\n","        self.l3 = nn.Linear(1024, 10)\n","    \n","    def forward(self, x):\n","        h = self.pool(self.relu(self.conv1(x)))\n","        h = self.pool(self.relu(self.conv2(h)))\n","        h = h.view(h.size()[0], -1)\n","        h = self.relu(self.l1(h))\n","        h = self.relu(self.l2(h))\n","        h = self.l3(h)\n","        return h"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8Dwuvfouzmd7"},"source":["## Create neural network\n","\n","Create the neural network defined by the program above.\n","\n","Call the CNN class to define the neural network model. If using the GPU （`use_cuda == True`）, the network model is placed in GPU memory. This makes it possible to perform operations using the GPU.\n","\n","We use stochastic gradient descent with momentum (SGD with momentum) as the optimization technique when training. We pass 0.01 as the argument of the learning rate parameter and 0.9 as the argument of the momentum parameter.\n","\n","Finally, `torchsummary.summary()` is used to display detailed information about the defined network.\n"]},{"cell_type":"code","metadata":{"id":"23m79Eq-zmjl"},"source":["model = CNN()\n","if use_cuda:\n","    model.cuda()\n","\n","optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n","\n","# display detiald information about the defined network\n","torchsummary.summary(model, (3, 32, 32))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MUNa9Xe79vAG"},"source":["## Training\n","\n","Carry out training by using the loaded CIFAR10 dataset and the created neural network.\n","\n","We set the data size for calculating errors for one pass (mini-batch size) as 64 and the number of training epochs as 10.\n","\n","Next, we define the data loader. The data loader uses the training dataset (`train_data`) that was loaded above and creates an object that reads the data in the mini-batch size as specified by the assignment statement below. For this training, we set `shuffle=True` to specify that the data is to be read randomly each time.\n","\n","Next, we set the error function. Because we are dealing with a classification problem here, we define `criterion` to be `CrossEntropyLoss` to calculate cross entropy error.\n","\n","Begin training.\n","\n","For each update, the data to be learned and the teacher data are given the names `image` and `label`, respectively. The training model is given an image and obtains the probability y for each class. The error between each class’s probability y and the teacher label is calculated by `criterion`. The recognition accuracy is also calculated. The error is then backpropagated by the backward function to update the neural network.\n"]},{"cell_type":"code","metadata":{"id":"68RE3RTa76-W"},"source":["# set the mini-batch size and training epochs\n","batch_size = 64\n","epoch_num = 10\n","n_iter = len(train_data) / batch_size\n","\n","# define data loader\n","train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n","\n","# set the error (loss) function\n","criterion = nn.CrossEntropyLoss()\n","if use_cuda:\n","    criterion.cuda()\n","\n","# switch to training mode\n","model.train()\n","\n","start = time()\n","for epoch in range(1, epoch_num+1):\n","    sum_loss = 0.0\n","    count = 0\n","    \n","    for image, label in train_loader:\n","        \n","        if use_cuda:\n","            image = image.cuda()\n","            label = label.cuda()\n","\n","        y = model(image)\n","\n","        loss = criterion(y, label)\n","        \n","        model.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        \n","        sum_loss += loss.item()\n","        \n","        pred = torch.argmax(y, dim=1)\n","        count += torch.sum(pred == label)\n","        \n","    print(\"epoch: {}, mean loss: {}, mean accuracy: {}, elapsed_time :{}\".format(epoch,\n","                                                                                 sum_loss / n_iter,\n","                                                                                 count.item() / len(train_loader),\n","                                                                                 time() - start))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"119eIrSmzmw6"},"source":["## Testing\n","Evaluate by using the trained network model on the testing data.\n"]},{"cell_type":"code","metadata":{"id":"yoYVMRGLzm1I"},"source":["# define data loader\n","test_loader = torch.utils.data.DataLoader(test_data, batch_size=100, shuffle=False)\n","\n","# switch evaluation mode\n","model.eval()\n","\n","# begin evaluation\n","count = 0\n","with torch.no_grad():\n","    for image, label in test_loader:\n","\n","        if use_cuda:\n","            image = image.cuda()\n","            label = label.cuda()\n","            \n","        y = model(image)\n","\n","        pred = torch.argmax(y, dim=1)\n","        count += torch.sum(pred == label)\n","\n","print(\"test accuracy: {}\".format(count.item() / 10000.))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Gzl4N5rC4j5u"},"source":["## Problems\n","\n","### 1. Change the neural network structure and confirm the change in recognition accuracy.\n","\n","**Hint: The following items can change the neural network structure.**\n","* The number of units in intermediate layers, convolution kernel size of convolution\n","* Number of layers\n","* The activation function\n","  * For example, `nn.Tanh()` or `nn.ReLU()`, `nn.LeakyReLU()`, etc.\n","  * Other activation functions that can be used in PyTorch are summarized on [this page](https://pytorch.org/docs/stable/nn.html#non-linear-activations-weighted-sum-nonlinearity).\n","\n","\n","### 2. Change training settings and confirm the change in recognition accuracy.\n","\n","**Hint: The following settings that can be changed in the program**\n","* Mini-batch size\n","* Number of training cycles (number of epochs)\n","* Learning rate\n","* Optimization method\n","  * Choices include `torch.optim.Adagrad()` and `torch.optim.Adam()`．\n","  * Optimization methods that can be used in PyTorch are summarized on [this page](https://pytorch.org/docs/stable/optim.html#algorithms).\n","\n","\n","### 3. Add types of data augmentation and carry out training.\n","\n","**Hint: You can change the data augmentation used for training in transform_train.**\n","\n","```python\n","transform_train = transforms.Compose([(Add augmentation you wish to use here) ,\n","                                      transforms.ToTensor()])\n","```\n","\n","Data augmentations you can use in PyTorch (torchvision) are summarized on [this page](https://pytorch.org/docs/stable/torchvision/transforms.html).\n","\n"]}]}